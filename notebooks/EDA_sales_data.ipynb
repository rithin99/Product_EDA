{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee752c70-e608-4240-86f4-659772d6bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f97870d-1449-4dd9-870c-f40723e4478f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
       " 0      1     1  05/02/2010      24924.50      False\n",
       " 1      1     1  12/02/2010      46039.49       True\n",
       " 2      1     1  19/02/2010      41595.55      False\n",
       " 3      1     1  26/02/2010      19403.54      False\n",
       " 4      1     1  05/03/2010      21827.90      False,\n",
       "    Store Type    Size\n",
       " 0      1    A  151315\n",
       " 1      2    A  202307\n",
       " 2      3    B   37392\n",
       " 3      4    A  205863\n",
       " 4      5    B   34875,\n",
       "    Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
       " 0      1  05/02/2010        42.31       2.572        NaN        NaN   \n",
       " 1      1  12/02/2010        38.51       2.548        NaN        NaN   \n",
       " 2      1  19/02/2010        39.93       2.514        NaN        NaN   \n",
       " 3      1  26/02/2010        46.63       2.561        NaN        NaN   \n",
       " 4      1  05/03/2010        46.50       2.625        NaN        NaN   \n",
       " \n",
       "    MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
       " 0        NaN        NaN        NaN  211.096358         8.106      False  \n",
       " 1        NaN        NaN        NaN  211.242170         8.106       True  \n",
       " 2        NaN        NaN        NaN  211.289143         8.106      False  \n",
       " 3        NaN        NaN        NaN  211.319643         8.106      False  \n",
       " 4        NaN        NaN        NaN  211.350143         8.106      False  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "sales_df = pd.read_csv(r'C:\\Users\\007ri\\Product_EDA/data/sales data-set.csv')\n",
    "stores_df = pd.read_csv(r'C:\\Users\\007ri\\Product_EDA/data/stores data-set.csv')\n",
    "features_df = pd.read_csv(r'C:\\Users\\007ri\\Product_EDA/data/Features data set.csv')\n",
    "\n",
    "# display 1st few rows\n",
    "sales_df.head(), stores_df.head(), features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e305c2ff-f10e-4569-b84a-d6c960f0f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store           0\n",
      "Dept            0\n",
      "Date            0\n",
      "Weekly_Sales    0\n",
      "IsHoliday       0\n",
      "dtype: int64\n",
      "Store           0\n",
      "Date            0\n",
      "Temperature     0\n",
      "Fuel_Price      0\n",
      "MarkDown1       0\n",
      "MarkDown2       0\n",
      "MarkDown3       0\n",
      "MarkDown4       0\n",
      "MarkDown5       0\n",
      "CPI             0\n",
      "Unemployment    0\n",
      "IsHoliday       0\n",
      "dtype: int64\n",
      "Store    0\n",
      "Type     0\n",
      "Size     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' columns to datetime format\n",
    "sales_df[\"Date\"] = pd.to_datetime(sales_df[\"Date\"], format=\"%d/%m/%Y\")\n",
    "features_df[\"Date\"] = pd.to_datetime(features_df[\"Date\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Fill missing values in Markdown columns with 0\n",
    "markdown_cols = [\"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\"]\n",
    "features_df[markdown_cols] = features_df[markdown_cols].fillna(0)\n",
    "\n",
    "# Fill CPI & Unemployment missing values using forward fill\n",
    "features_df[\"CPI\"] = features_df[\"CPI\"].ffill()\n",
    "features_df[\"Unemployment\"] = features_df[\"Unemployment\"].ffill()\n",
    "\n",
    "# Check for missing values\n",
    "print(sales_df.isnull().sum())\n",
    "print(features_df.isnull().sum())\n",
    "print(stores_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951c7b1e-0f7f-453e-8db8-7311fbe3c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 421570 entries, 0 to 421569\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   Store         421570 non-null  int64         \n",
      " 1   Dept          421570 non-null  int64         \n",
      " 2   Date          421570 non-null  datetime64[ns]\n",
      " 3   Weekly_Sales  421570 non-null  float64       \n",
      " 4   IsHoliday_x   421570 non-null  bool          \n",
      " 5   Type          421570 non-null  object        \n",
      " 6   Size          421570 non-null  int64         \n",
      " 7   Temperature   421570 non-null  float64       \n",
      " 8   Fuel_Price    421570 non-null  float64       \n",
      " 9   MarkDown1     421570 non-null  float64       \n",
      " 10  MarkDown2     421570 non-null  float64       \n",
      " 11  MarkDown3     421570 non-null  float64       \n",
      " 12  MarkDown4     421570 non-null  float64       \n",
      " 13  MarkDown5     421570 non-null  float64       \n",
      " 14  CPI           421570 non-null  float64       \n",
      " 15  Unemployment  421570 non-null  float64       \n",
      " 16  IsHoliday_y   421570 non-null  bool          \n",
      "dtypes: bool(2), datetime64[ns](1), float64(10), int64(3), object(1)\n",
      "memory usage: 49.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge sales with store details\n",
    "merged_df = sales_df.merge(stores_df, on=\"Store\", how=\"left\")\n",
    "\n",
    "# Merge with features dataset\n",
    "merged_df = merged_df.merge(features_df, on=[\"Store\", \"Date\"], how=\"left\")\n",
    "\n",
    "# Display the merged data structure\n",
    "print(merged_df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
